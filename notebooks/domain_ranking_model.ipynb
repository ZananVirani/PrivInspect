{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead7649d",
   "metadata": {},
   "source": [
    "# Domain Ranking Model - DuckDuckGo TrackerRadar Integration\n",
    "\n",
    "This notebook demonstrates the complete end-to-end ML pipeline for domain risk scoring using DuckDuckGo TrackerRadar data.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Our domain ranking model uses machine learning to predict domain tracking intensity based on:\n",
    "- Domain characteristics and reputation\n",
    "- TrackerRadar data for known tracking behaviors\n",
    "- Privacy policies and data collection practices\n",
    "\n",
    "The model outputs safety scores (0-100) that integrate with our privacy analysis heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cff0a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'backend'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"Python path includes: {sys.path[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d1dd61",
   "metadata": {},
   "source": [
    "## Step 1: Load and Explore TrackerRadar Data\n",
    "\n",
    "First, let's load the DuckDuckGo TrackerRadar data and explore its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e79c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training script components\n",
    "from scripts.train_domain_model import TrackerRadarParser, TargetConstructor, DomainRiskModel\n",
    "\n",
    "# Initialize the parser and load TrackerRadar data\n",
    "parser = TrackerRadarParser()\n",
    "\n",
    "print(\"Downloading DuckDuckGo TrackerRadar data...\")\n",
    "tracker_data = parser.download_tracker_radar()\n",
    "print(f\"‚úÖ Downloaded data with {len(tracker_data.get('domains', {}))} domains\")\n",
    "\n",
    "# Parse domains and display sample data\n",
    "parsed_domains = parser.parse_domains(tracker_data)\n",
    "print(f\"‚úÖ Parsed {len(parsed_domains)} domains with features\")\n",
    "\n",
    "# Show sample parsed domains\n",
    "print(\"\\nSample domain data:\")\n",
    "for i, (domain, features) in enumerate(list(parsed_domains.items())[:5]):\n",
    "    print(f\"{i+1}. {domain}:\")\n",
    "    for key, value in features.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a49a472",
   "metadata": {},
   "source": [
    "## Step 2: Generate Training Targets\n",
    "\n",
    "Now let's construct tracking intensity targets for our ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca7f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate tracking intensity targets\n",
    "target_constructor = TargetConstructor()\n",
    "targets = target_constructor.construct_targets(tracker_data)\n",
    "\n",
    "print(f\"‚úÖ Generated {len(targets)} tracking intensity targets\")\n",
    "print(f\"Target range: {min(targets.values()):.3f} to {max(targets.values()):.3f}\")\n",
    "print(f\"Mean target: {np.mean(list(targets.values())):.3f}\")\n",
    "\n",
    "# Show distribution of targets\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(list(targets.values()), bins=30, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Tracking Intensity')\n",
    "plt.ylabel('Number of Domains')\n",
    "plt.title('Distribution of Tracking Intensity Targets')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Show sample targets\n",
    "print(\"\\nSample tracking intensity scores:\")\n",
    "sorted_targets = sorted(targets.items(), key=lambda x: x[1], reverse=True)\n",
    "for i, (domain, score) in enumerate(sorted_targets[:10]):\n",
    "    print(f\"{i+1}. {domain}: {score:.3f}\")\n",
    "print(f\"...\")\n",
    "for i, (domain, score) in enumerate(sorted_targets[-5:]):\n",
    "    print(f\"{len(sorted_targets)-4+i}. {domain}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df93adf8",
   "metadata": {},
   "source": [
    "## Step 3: Train Domain Risk Model\n",
    "\n",
    "Let's train our machine learning model using the parsed features and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the domain risk model\n",
    "model = DomainRiskModel(model_type='lightgbm')\n",
    "\n",
    "print(\"Training domain risk model...\")\n",
    "model.train(parsed_domains, targets)\n",
    "print(\"‚úÖ Model training completed!\")\n",
    "\n",
    "# Display model performance\n",
    "print(f\"Training R¬≤ score: {model.r2_score:.4f}\")\n",
    "print(f\"Training RMSE: {model.rmse:.4f}\")\n",
    "print(f\"Number of features: {len(model.feature_names_)}\")\n",
    "\n",
    "# Show feature importance (top 15)\n",
    "feature_importance = model.get_feature_importance()\n",
    "print(\"\\nTop 15 most important features:\")\n",
    "for i, (feature, importance) in enumerate(feature_importance[:15]):\n",
    "    print(f\"{i+1:2d}. {feature}: {importance:.4f}\")\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "features, importances = zip(*feature_importance[:20])\n",
    "plt.barh(range(len(features)), importances)\n",
    "plt.yticks(range(len(features)), features)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 20 Most Important Features')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf890a22",
   "metadata": {},
   "source": [
    "## Step 4: Test Model Predictions\n",
    "\n",
    "Let's test our model with some example domains and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4269cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with example domains\n",
    "test_domains = [\n",
    "    'google-analytics.com',\n",
    "    'facebook.com', \n",
    "    'doubleclick.net',\n",
    "    'github.com',\n",
    "    'stackoverflow.com',\n",
    "    'wikipedia.org',\n",
    "    'amazon.com',\n",
    "    'cloudflare.com'\n",
    "]\n",
    "\n",
    "print(\"Testing model predictions on example domains:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_results = []\n",
    "for domain in test_domains:\n",
    "    # Get tracking intensity prediction (0-1)\n",
    "    tracking_intensity = model.predict_single_domain(domain)\n",
    "    \n",
    "    # Convert to safety score (0-100, higher is safer)\n",
    "    safety_score = (1 - tracking_intensity) * 100\n",
    "    \n",
    "    test_results.append({\n",
    "        'domain': domain,\n",
    "        'tracking_intensity': tracking_intensity,\n",
    "        'safety_score': safety_score\n",
    "    })\n",
    "    \n",
    "    print(f\"{domain:25} | Intensity: {tracking_intensity:.3f} | Safety: {safety_score:.1f}/100\")\n",
    "\n",
    "# Create visualization\n",
    "df_results = pd.DataFrame(test_results)\n",
    "df_results = df_results.sort_values('safety_score')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.barh(df_results['domain'], df_results['safety_score'])\n",
    "\n",
    "# Color code bars (red for low safety, green for high safety)\n",
    "for i, bar in enumerate(bars):\n",
    "    score = df_results.iloc[i]['safety_score']\n",
    "    if score >= 80:\n",
    "        bar.set_color('green')\n",
    "    elif score >= 60:\n",
    "        bar.set_color('orange') \n",
    "    else:\n",
    "        bar.set_color('red')\n",
    "\n",
    "plt.xlabel('Safety Score (0-100)')\n",
    "plt.title('Domain Safety Scores - Model Predictions')\n",
    "plt.xlim(0, 100)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c83d70",
   "metadata": {},
   "source": [
    "## Step 5: Save Model and Test Integration\n",
    "\n",
    "Finally, let's save the trained model and test the FastAPI integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23e962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "models_dir = os.path.join('..', 'backend', 'models')\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "model_path = model.save_model(models_dir)\n",
    "print(f\"‚úÖ Model saved to: {model_path}\")\n",
    "\n",
    "# Test the ML scoring integration\n",
    "print(\"\\nTesting ML scoring integration...\")\n",
    "try:\n",
    "    from app.ml_scoring import DomainScoringService, get_ml_score_for_page\n",
    "    from app.models import PrivacyFeatures\n",
    "    \n",
    "    # Create sample privacy features\n",
    "    sample_features = PrivacyFeatures(\n",
    "        page_url=\"https://example.com\",\n",
    "        num_third_party_domains=5,\n",
    "        num_third_party_scripts=8,\n",
    "        num_third_party_cookies=3,\n",
    "        fraction_third_party_requests=0.4,\n",
    "        num_known_tracker_domains=2,\n",
    "        num_persistent_cookies=4,\n",
    "        has_analytics_global=1,\n",
    "        num_inline_scripts=3,\n",
    "        fingerprinting_flag=0,\n",
    "        tracker_script_ratio=0.25,\n",
    "        third_party_domains=[\"google-analytics.com\", \"facebook.com\", \"doubleclick.net\", \"amazon.com\", \"cloudflare.com\"],\n",
    "        additional_data={}\n",
    "    )\n",
    "    \n",
    "    # Get ML score\n",
    "    ml_score = get_ml_score_for_page(sample_features)\n",
    "    print(f\"‚úÖ ML scoring successful! Score: {ml_score:.1f}/100\")\n",
    "    \n",
    "    print(\"\\nDomain-level predictions for this page:\")\n",
    "    for domain in sample_features.third_party_domains:\n",
    "        # Test individual domain scoring\n",
    "        service = DomainScoringService()\n",
    "        domains_data = [{\n",
    "            'domain': domain,\n",
    "            'frequency': 1,\n",
    "            'is_known_tracker': domain in ['google-analytics.com', 'facebook.com', 'doubleclick.net']\n",
    "        }]\n",
    "        result = service.score_domains(domains_data)\n",
    "        print(f\"  {domain}: {result['weighted_score']:.1f}/100\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Integration test failed: {e}\")\n",
    "    \n",
    "print(\"\\nüéâ Domain ranking model pipeline completed successfully!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. The model is now integrated into the FastAPI backend\")\n",
    "print(\"2. Privacy scores will use real ML predictions instead of fixed values\")\n",
    "print(\"3. The ML scoring API is available at /api/v1/model/ endpoints\")\n",
    "print(\"4. Heuristic penalties are now reduced by half for better balance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b93cec",
   "metadata": {},
   "source": [
    "## Step 6: Retrain with Latest Aggressive Improvements\n",
    "\n",
    "Let's retrain the model with the latest aggressive improvements and verify the entire pipeline works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3553e740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Retraining model with latest aggressive improvements...\n",
      "This includes:\n",
      "- Enhanced category-based fingerprinting detection\n",
      "- 70% reduction in num_resources importance\n",
      "- Legitimate domain allowlisting\n",
      "- Very aggressive multi-category tracking scoring\n",
      "\n",
      "‚ùå Model retraining failed!\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/Users/zananvirani/Desktop/PrivInspect/scripts/train_domain_model.py\"\u001b[0m, line \u001b[35m23\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    import pandas as pd\n",
      "\u001b[1;35mModuleNotFoundError\u001b[0m: \u001b[35mNo module named 'pandas'\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrain the model using the latest training script with aggressive improvements\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "print(\"üîÑ Retraining model with latest aggressive improvements...\")\n",
    "print(\"This includes:\")\n",
    "print(\"- Enhanced category-based fingerprinting detection\")\n",
    "print(\"- 70% reduction in num_resources importance\")\n",
    "print(\"- Legitimate domain allowlisting\")\n",
    "print(\"- Very aggressive multi-category tracking scoring\")\n",
    "print()\n",
    "\n",
    "# Change to project root and run the training script\n",
    "os.chdir('..')\n",
    "result = subprocess.run(['python3', 'scripts/train_domain_model.py'], \n",
    "                       capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úÖ Model retraining completed successfully!\")\n",
    "    print(result.stdout.split('\\n')[-20:])  # Show last 20 lines\n",
    "else:\n",
    "    print(\"‚ùå Model retraining failed!\")\n",
    "    print(result.stderr)\n",
    "    \n",
    "# Change back to notebooks directory\n",
    "os.chdir('notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bdfdee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Test the retrained model on key domains\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'joblib'"
     ]
    }
   ],
   "source": [
    "# Test the retrained model on key domains\n",
    "import joblib\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "print(\"üß™ Testing retrained model on key domains...\")\n",
    "\n",
    "# Load the retrained model\n",
    "try:\n",
    "    model_data = joblib.load('../models/domain_risk_model.pkl')\n",
    "    model = model_data['model']\n",
    "    scaler = model_data['scaler']\n",
    "    \n",
    "    # Load features\n",
    "    with open('../models/domain_features.json', 'r') as f:\n",
    "        all_features = json.load(f)\n",
    "    \n",
    "    print(f\"‚úÖ Loaded retrained model with {len(all_features)} domains\")\n",
    "    \n",
    "    # Test key domains\n",
    "    test_domains = [\n",
    "        'addthis.com',           # Previously problematic\n",
    "        'doubleclick.net',       # Should be very low safety\n",
    "        'googletagmanager.com',  # Should be very low safety\n",
    "        'facebook.com',          # Should be very low safety\n",
    "        'google-analytics.com',  # Should be very low safety\n",
    "        'wikipedia.org',         # Should be high safety\n",
    "        'archive.org',           # Should be high safety\n",
    "        'github.com',            # Should be high safety\n",
    "        'mozilla.org',           # Should be high safety\n",
    "        'firebaseremoteconfig.googleapis.com'  # From ChatGPT example\n",
    "    ]\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*70)\n",
    "    print(\"RETRAINED MODEL TEST RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    tracking_scores = []\n",
    "    legitimate_scores = []\n",
    "    \n",
    "    for domain in test_domains:\n",
    "        if domain in all_features:\n",
    "            features = all_features[domain]\n",
    "            feature_vector = [\n",
    "                features['fingerprinting'],\n",
    "                features['cookies_prevalence'], \n",
    "                features['global_prevalence'],\n",
    "                features['num_sites'],\n",
    "                features['num_subdomains'],\n",
    "                features['num_cnames'],\n",
    "                features['num_resources'],\n",
    "                features['num_top_initiators'],\n",
    "                features['owner_present'],\n",
    "                features['resource_type_script_count'],\n",
    "                features['resource_type_xhr_count'],\n",
    "                features['resource_type_image_count'],\n",
    "                features['resource_type_css_count'],\n",
    "                features['resource_type_font_count'],\n",
    "                features['resource_type_media_count'],\n",
    "                features['avg_resource_fingerprinting'],\n",
    "                features['has_example_sites']\n",
    "            ]\n",
    "            \n",
    "            # Scale features and predict\n",
    "            scaled_features = scaler.transform([feature_vector])\n",
    "            prediction = model.predict(scaled_features)[0]\n",
    "            \n",
    "            # Convert to safety score (0-100, higher = safer)\n",
    "            safety_score = prediction * 100\n",
    "            \n",
    "            # Categorize for analysis\n",
    "            if domain in ['wikipedia.org', 'archive.org', 'github.com', 'mozilla.org']:\n",
    "                legitimate_scores.append(safety_score)\n",
    "                category = \"üü¢ LEGITIMATE\"\n",
    "            else:\n",
    "                tracking_scores.append(safety_score)\n",
    "                category = \"üî¥ TRACKING\"\n",
    "            \n",
    "            # Get enhanced fingerprinting for analysis\n",
    "            enhanced_fp = features['fingerprinting']\n",
    "            \n",
    "            print(f\"{domain:35} | {safety_score:5.1f}/100 | Enhanced FP: {enhanced_fp:3.1f} | {category}\")\n",
    "        else:\n",
    "            print(f\"{domain:35} | NOT FOUND in dataset\")\n",
    "    \n",
    "    # Performance summary\n",
    "    print(\"\\\\n\" + \"=\"*70)\n",
    "    print(\"PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if tracking_scores:\n",
    "        print(f\"üî¥ TRACKING DOMAINS:\")\n",
    "        print(f\"   Average: {np.mean(tracking_scores):.1f}/100 (should be low)\")\n",
    "        print(f\"   Range: {min(tracking_scores):.1f} - {max(tracking_scores):.1f}/100\")\n",
    "        \n",
    "    if legitimate_scores:\n",
    "        print(f\"üü¢ LEGITIMATE DOMAINS:\")\n",
    "        print(f\"   Average: {np.mean(legitimate_scores):.1f}/100 (should be high)\")\n",
    "        print(f\"   Range: {min(legitimate_scores):.1f} - {max(legitimate_scores):.1f}/100\")\n",
    "    \n",
    "    # Check AddThis specifically\n",
    "    if 'addthis.com' in all_features and 'addthis.com' in [d for d in test_domains]:\n",
    "        addthis_score = next(score for score, domain in zip(tracking_scores + legitimate_scores, test_domains) \n",
    "                           if domain == 'addthis.com' and domain in all_features)\n",
    "        print(f\"\\\\nüéØ ADDTHIS IMPROVEMENT: {addthis_score:.1f}/100 (target: <30/100)\")\n",
    "        if addthis_score < 30:\n",
    "            print(\"   ‚úÖ SUCCESS: AddThis properly classified as risky!\")\n",
    "        elif addthis_score < 60:\n",
    "            print(\"   üü° GOOD: Major improvement from 100/100\")\n",
    "        else:\n",
    "            print(\"   ‚ùå NEEDS MORE WORK: Still too high\")\n",
    "    \n",
    "    print(\"\\\\n‚úÖ Retrained model testing completed!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error testing retrained model: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f51c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test full integration with gentler heuristic penalties\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../backend')\n",
    "\n",
    "print(\"üîó Testing full integration with gentler heuristic penalties...\")\n",
    "\n",
    "try:\n",
    "    from app.ml_scoring import get_ml_score_for_page, domain_scoring_service, initialize_domain_scoring\n",
    "    from app.models import AnalyzeRequest, NetworkRequest, Script, Cookie\n",
    "    \n",
    "    # Initialize the ML scoring service\n",
    "    initialize_domain_scoring()\n",
    "    \n",
    "    # Create a realistic test scenario (simulating ChatGPT page)\n",
    "    chatgpt_request = AnalyzeRequest(\n",
    "        page_url=\"https://chatgpt.com\",\n",
    "        network_requests=[\n",
    "            NetworkRequest(url=\"https://ab.chatgpt.com/v1/rgstr\", domain=\"ab.chatgpt.com\", method=\"POST\", type=\"xmlhttprequest\"),\n",
    "            NetworkRequest(url=\"https://ab.chatgpt.com/v1/rgstr\", domain=\"ab.chatgpt.com\", method=\"POST\", type=\"xmlhttprequest\"),\n",
    "            NetworkRequest(url=\"https://ab.chatgpt.com/v1/rgstr\", domain=\"ab.chatgpt.com\", method=\"POST\", type=\"xmlhttprequest\"),\n",
    "            NetworkRequest(url=\"https://ab.chatgpt.com/v1/rgstr\", domain=\"ab.chatgpt.com\", method=\"POST\", type=\"xmlhttprequest\"),\n",
    "            NetworkRequest(url=\"https://ab.chatgpt.com/v1/rgstr\", domain=\"ab.chatgpt.com\", method=\"POST\", type=\"xmlhttprequest\"),\n",
    "            NetworkRequest(url=\"https://firebaseremoteconfig.googleapis.com/v1/projects/castify-storage/namespaces/firebase:fetch\", domain=\"firebaseremoteconfig.googleapis.com\", method=\"POST\", type=\"xmlhttprequest\"),\n",
    "            NetworkRequest(url=\"https://firebaseremoteconfig.googleapis.com/v1/projects/castify-storage/namespaces/firebase:fetch\", domain=\"firebaseremoteconfig.googleapis.com\", method=\"OPTIONS\", type=\"xmlhttprequest\"),\n",
    "        ],\n",
    "        scripts=[],\n",
    "        raw_cookies=[],\n",
    "        additional_data={}\n",
    "    )\n",
    "    \n",
    "    # Test ML scoring\n",
    "    ml_score = get_ml_score_for_page(chatgpt_request)\n",
    "    print(f\"‚úÖ ML Score: {ml_score:.2f}/100\")\n",
    "    \n",
    "    # Test individual domain scoring\n",
    "    domain_counts = domain_scoring_service.extract_domains_from_analyze_request(chatgpt_request)\n",
    "    result = domain_scoring_service.score_domains(domain_counts)\n",
    "    \n",
    "    print(f\"\\\\nüìä DETAILED SCORING RESULTS:\")\n",
    "    print(f\"Total domains found: {result.total_domains}\")\n",
    "    print(f\"Known domains: {result.known_domains}\")\n",
    "    print(f\"Unknown domains: {result.unknown_domains}\")\n",
    "    print(f\"Aggregated ML score: {result.aggregated_ml_score:.2f}/100\")\n",
    "    \n",
    "    print(f\"\\\\nDomain breakdown:\")\n",
    "    for domain_score in result.domains:\n",
    "        known_status = \"‚úÖ Known\" if domain_score.domain_known else \"‚ùå Unknown\"\n",
    "        print(f\"  {domain_score.domain:35} | Count: {domain_score.count} | Score: {domain_score.domain_safe_score:5.1f}/100 | {known_status}\")\n",
    "    \n",
    "    # Now test complete privacy scoring pipeline\n",
    "    print(f\"\\\\nüßÆ Testing complete privacy scoring with gentler penalties...\")\n",
    "    \n",
    "    # This would normally be done in the FastAPI endpoint, but let's test the logic\n",
    "    from app.routers.analyze import extract_privacy_features, compute_privacy_score\n",
    "    \n",
    "    # Extract features (this simulates what the analyze endpoint does)\n",
    "    features = extract_privacy_features(chatgpt_request)\n",
    "    \n",
    "    # Compute privacy score with gentler penalties\n",
    "    privacy_result = compute_privacy_score(features, chatgpt_request)\n",
    "    \n",
    "    print(f\"\\\\nüéØ FINAL PRIVACY ANALYSIS:\")\n",
    "    print(f\"ML Base Score: {privacy_result['breakdown']['ml_base_score']:.2f}/100\")\n",
    "    print(f\"Total Penalty: {privacy_result['breakdown']['total_penalty_applied']:.2f}\")\n",
    "    print(f\"Final Score: {privacy_result['score']:.2f}/100\")\n",
    "    print(f\"Grade: {privacy_result['grade_letter']}\")\n",
    "    \n",
    "    print(f\"\\\\nPenalty breakdown (gentler system):\")\n",
    "    for penalty_type, value in privacy_result['breakdown']['individual_penalties'].items():\n",
    "        if value != 0:\n",
    "            print(f\"  {penalty_type}: {value:.1f}\")\n",
    "    \n",
    "    if privacy_result['breakdown']['penalty_cap_applied']:\n",
    "        print(f\"\\\\n‚ö†Ô∏è Penalty cap applied (limited to -10.0)\")\n",
    "    \n",
    "    print(f\"\\\\n‚úÖ Full integration test completed successfully!\")\n",
    "    print(f\"üéâ The system now provides much fairer scoring with gentler penalties!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Integration test failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f7be38",
   "metadata": {},
   "source": [
    "# Domain Ranking Model using DuckDuckGo TrackerRadar\n",
    "\n",
    "This notebook implements an end-to-end machine learning pipeline that:\n",
    "1. Downloads and parses DuckDuckGo TrackerRadar data\n",
    "2. Engineers domain-level features for privacy risk assessment\n",
    "3. Trains a gradient boosted regressor to predict tracking intensity\n",
    "4. Integrates with FastAPI for real-time domain scoring\n",
    "5. Provides ML-based privacy scores for web page analysis\n",
    "\n",
    "The trained model will be integrated into the PrivInspect backend to replace the placeholder ML score (currently fixed at 100) with actual domain-based risk predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ec9f42",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies\n",
    "\n",
    "Install and import all required libraries for data processing, machine learning, and API integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caab918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run this if packages are not installed)\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip if not already installed\"\"\"\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# List of required packages\n",
    "packages = [\n",
    "    'pandas', 'numpy', 'scikit-learn', 'lightgbm', 'xgboost', \n",
    "    'fastapi', 'joblib', 'requests', 'tqdm', 'matplotlib', 'seaborn'\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"All packages installed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
